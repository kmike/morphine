Принципы работы
===============

Неоднозначность по морфологическим характеристикам снимается отдельно
для различных характеристик.

pymorphy2==0.8 со словарем от 6 июня 2014г допускает следующие ошибки:

* Ошибки на падеж: 22702
* Ошибки на часть речи: 9029
* Ошибки на род: 8317
* Ошибки на число: 7883
* Ошибки на одушевленность: 5808
* Ошибки на транзитивность: 1698
* Ошибки на время: 1648
* Ошибки на лицо: 1399
* Ошибки на аббривеатуры: 869


Возможных тегов много (тысячи), тренировочных данных мало.

Идея такая: для разных типов ошибок построить отдельные классификаторы;
объединить их затем в один.

Благодаря этому каждый классификатор будет иметь больше тренировочных данных
(неоднозначность не обязательно должна быть снята полностью), и наборы
выходных значений будут небольшими.

Зависимости > 1 токена
======================

Для того, чтобы учитывать зависимости глубиной > 1 токена,
можно использовать вероятности тегов (предсказанные либо той же самой, либо
упрощенной моделью) как фичи.

См. Yu, Dong, Shizhen Wang, and Li Deng.
“Sequential Labeling Using Deep-Structured Conditional Random Fields.”
In Topics Signal Processing (Special Issue on Statistical Learning Methods
for Speech and Language Processing), 2010.

Объединение предсказаний
========================

??

* Сложить вероятности от различных классификаторов;
* сложить вероятности с весами, подобрать веса автоматически с помощью
  линейной модели.


Оценка результатов
==================

1. Разобрать НКРЯ;
2. записать все в файл (с информацией о том, что использовалось в эксперименте?);
3. посчитать оценки (отдельным скриптом?).

Фичи
====

* Граммемы в поз. i;
* пары граммем в поз. i;
* токен i; токен i-1; токен i-2; токен i+1 (и т.д.?);
* предыдущие/последующие граммемы / пары граммем;
* комбинации текущих и предыдущих граммем.
* начало предложения;
* конец предложения.

Все граммемы - с весами от pymorphy2. Для граммем, в которых pymorphy2 уверен,
либо задрать веса, либо добавить отдельные фичи.

Еще идеи для фич:

* сложные предлоги из словаря (пары слов могут "поймать" их,
  но тренировочных данных маловато);
* фичи, которые "пропускают" некоторые токены, когда смотрят
  вперед или назад - например, перепрыгивающие через пунктуацию или союз "и".


Было бы удобно:

* иметь набор фич, который можно комбинировать;
* иметь "высокоуровневые" шаблоны;
* иметь возможность сохранять их в pickle вместе с моделью.

todo - починить webstruct: убрать зависимость от scikit-learn,
убрать зависимость от seqlearn и numpy, отвязать от html.

Или: скопипастить оттуда полезные части.

Нерешенные задачи
=================

1. Разделение текста на предложения.


Способы решения отдельных задач
===============================

Падеж
-----

CRF

* падежи рядом стоящих слов (согласование по падежу);
* предлоги.

Часть речи
----------

CRF

* части речи рядом стоящих слов (вероятные цепочки) - наверное, +-2;
* ?

Род
---

CRF

* род рядом стоящих слов (согласование по родам);
* ?

Число
-----

CRF

* числа рядом стоящих слов (согласование по числу);


Одушевленность
--------------

??

Транзитивность
--------------

* падежи рядом стоящих слов
* ?

Время
-----

??

Лицо
----

??

Аббривеатуры
------------

??

Остальные граммемы
------------------

??
