{
 "metadata": {
  "name": "",
  "signature": "sha256:d0e7425a96b958d8f3bc2cf41d03c3c86af65a97d7a20332e28edc61d5b92dde"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "from itertools import islice, chain\n",
      "from collections import defaultdict\n",
      "import pycrfsuite\n",
      "import pymorphy2\n",
      "import opencorpora\n",
      "\n",
      "m = pymorphy2.MorphAnalyzer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls -lh *.xml"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-rw-r--r--  1 kmike  staff   6.4M May 18 17:00 annot.opcorpora.no_ambig.xml\r\n",
        "-rw-r--r--  1 kmike  staff   434M May 18 17:00 annot.opcorpora.xml\r\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!opencorpora download -d -o annot.opcorpora.no_ambig.xml"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating annot.opcorpora.no_ambig.xml from http://opencorpora.org/files/export/annot/annot.opcorpora.no_ambig.xml.bz2\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "..\r\n",
        "Done.\r\n"
       ]
      }
     ],
     "prompt_number": 282
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!opencorpora download"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Creating annot.opcorpora.xml from http://opencorpora.org/files/export/annot/annot.opcorpora.xml.bz2\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\r\n",
        "Done.\r\n"
       ]
      }
     ],
     "prompt_number": 283
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus_noambig = opencorpora.CorpusReader('annot.opcorpora.no_ambig.xml')\n",
      "corpus_full = opencorpora.CorpusReader('annot.opcorpora.xml', use_cache=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list(islice(corpus_full.iter_parsed_sents(), 6, 7))[0][:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[('\u0412\u043f\u0440\u043e\u0447\u0435\u043c', [('\u0432\u043f\u0440\u043e\u0447\u0435\u043c', 'CONJ,Prnt')]),\n",
        " (',', [(',', 'PNCT')]),\n",
        " ('\u043d\u0430', [('\u043d\u0430', 'PREP')]),\n",
        " ('\u043a\u0430\u043d\u0430\u043b\u0435', [('\u043a\u0430\u043d\u0430\u043b', 'NOUN,inan,masc,sing,loct')]),\n",
        " ('\u00ab', [('\u00ab', 'PNCT')]),\n",
        " ('\u041a\u0443\u043b\u044c\u0442\u0443\u0440\u0430', [('\u043a\u0443\u043b\u044c\u0442\u0443\u0440\u0430', 'NOUN,inan,femn,sing,nomn')]),\n",
        " ('\u00bb', [('\u00bb', 'PNCT')]),\n",
        " ('\u0432', [('\u0432', 'PREP')]),\n",
        " ('\u0440\u043e\u043b\u0438', [('\u0440\u043e\u043b\u044c', 'NOUN,inan,femn,sing,loct')]),\n",
        " ('\u0442\u0435\u043b\u0435\u0432\u0435\u0434\u0443\u0449\u0438\u0445', [('\u0442\u0435\u043b\u0435\u0432\u0435\u0434\u0443\u0449\u0430\u044f', 'NOUN,anim,femn,plur,gent')])]"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sents_opcorpora = [sent for sent in corpus_noambig.iter_tagged_sents() \n",
      "#                    if not any(tag=='UNKN' for tok, tag in sent)]\n",
      "# sents_opcorpora = [[(tok, m.TagClass(tag)) for tok, tag in sent if tag != 'PNCT'] for sent in sents_opcorpora]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# len(sents_opcorpora)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MICROCORPUS_GLOB = '../../microcorpus/data/done/*.txt'\n",
      "\n",
      "def load_microcorpus(path, out_func, remove_pnct=True):\n",
      "    for fn in glob.glob(path):\n",
      "        with open(fn, 'r', encoding='utf8') as f:\n",
      "            sent = []\n",
      "            for line in f:\n",
      "                token, tag = line.split(None, 1)\n",
      "                if remove_pnct and tag.strip() == 'PNCT':\n",
      "                    continue                    \n",
      "                tag = m.TagClass(tag.strip())                \n",
      "                sent.append((token, out_func(tag)))\n",
      "            yield sent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_outvalue(tag):\n",
      "    case = str(tag.case or 'NA')\n",
      "    case = m.TagClass.RARE_CASES.get(case, case)\n",
      "    return case\n",
      "    \n",
      "#     number = str(tag.number or 'NA')\n",
      "#     return '%s,%s' % (case, number)\n",
      "\n",
      "#     return case\n",
      "#     return str(tag.POS or 'OTHER')\n",
      "#     return str(tag.gender or 'NA')\n",
      "#     case = str(tag.case or '')\n",
      "#     case = m.TagClass.RARE_CASES.get(case, case)\n",
      "#     if not case:\n",
      "#         return str(tag._POS)    \n",
      "#     return \"%s,%s\" % (tag._POS, case)\n",
      "\n",
      "def _has_tag(parsed_sent, tag):\n",
      "    return any(tag == ptag for token, parses in parsed_sent for norm, ptag in parses)\n",
      "\n",
      "def _has_unkn(parsed_sent):\n",
      "    return _has_tag(parsed_sent, 'UNKN')\n",
      "\n",
      "def get_unambig_sents(parsed_sents, out_func, remove_pnct=True):\n",
      "    for sent in parsed_sents:\n",
      "        if _has_unkn(sent):\n",
      "            continue\n",
      "\n",
      "        processed_sent = []\n",
      "        for token, parses in sent:\n",
      "            if remove_pnct and any(tag=='PNCT' for norm, tag in parses):\n",
      "                continue                \n",
      "            seen_y = list(set(out_func(m.TagClass(tag)) for norm, tag in parses))\n",
      "            if len(seen_y) != 1:\n",
      "                # ambiguous\n",
      "                break\n",
      "#             if any('Init' in tag for tag in m.tag(token)):\n",
      "#                 # Initials are not handled in corpora yet,\n",
      "#                 # so pymorphy2 probability estimates are wrong\n",
      "#                 # for them.\n",
      "#                 break\n",
      "            processed_sent.append((token, seen_y[0]))\n",
      "        else:\n",
      "            if processed_sent:\n",
      "                yield processed_sent\n",
      "\n",
      "def getY(sents):\n",
      "    return [[out for token, out in sent] for sent in sents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for sent in get_unambig_sents(islice(corpus_full.iter_parsed_sents(), 200, 230), get_outvalue):\n",
      "    print(sent, end='\\n\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('\u0410', 'NA'), ('\u043f\u0440\u0438\u0445\u043e\u0434\u0438\u0442\u0441\u044f', 'NA')]\n",
        "\n",
        "[('\u0410', 'NA'), ('\u043c\u043e\u0436\u0435\u0442', 'NA'), ('\u0438', 'NA'), ('\u043d\u0435', 'NA'), ('\u0443\u0432\u043b\u0435\u043a\u0430\u0435\u0442\u0441\u044f', 'NA'), ('\u0430', 'NA'), ('\u043f\u0440\u043e\u0441\u0442\u043e', 'NA'), ('\u0440\u0435\u0437\u0432\u0438\u0442\u0441\u044f', 'NA')]\n",
        "\n",
        "[('\u0421\u043e\u0431\u043b\u0430\u0437\u043d\u044f\u0435\u0442', 'NA')]\n",
        "\n",
        "[('\u0428\u0430\u043b\u0438\u0442', 'NA')]\n",
        "\n",
        "[('\u0424\u0440\u0438\u043a', 'nomn')]\n",
        "\n",
        "[('\u0420\u0430\u0434\u0438', 'NA'), ('\u043d\u0435\u0433\u043e', 'gent'), ('\u0441\u0442\u043e\u0438\u0442', 'NA'), ('\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c', 'NA'), ('\u044d\u0442\u0443', 'accs'), ('\u043d\u0435', 'NA'), ('\u0441\u0430\u043c\u0443\u044e', 'accs'), ('\u0438\u043d\u0442\u0435\u0440\u0435\u0441\u043d\u0443\u044e', 'accs'), ('\u043a\u0430\u0440\u0442\u0438\u043d\u0443', 'accs')]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "sents_opcorpora_raw = list(\n",
      "    get_unambig_sents(corpus_full.iter_parsed_sents(), get_outvalue, remove_pnct=False)\n",
      ")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " "
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sents_opcorpora = [s for s in sents_opcorpora_raw if len(s) > 1]\n",
      "len(sents_opcorpora_raw), len(sents_opcorpora)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "(7609, 7247)"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TRAIN_SIZE = 60\n",
      "\n",
      "sents_train = sents_opcorpora\n",
      "sents_test = list(load_microcorpus(MICROCORPUS_GLOB, get_outvalue, remove_pnct=False))\n",
      "\n",
      "y_train = getY(sents_train)\n",
      "y_test = getY(sents_test)\n",
      "\n",
      "# sents = list(load_microcorpus(MICROCORPUS_GLOB))\n",
      "# sents_train, sents_test = sents[:TRAIN_SIZE], sents[TRAIN_SIZE:]\n",
      "\n",
      "# y = [[get_case(tag) for token, tag in sent] for sent in sents]\n",
      "# y_train, y_test = y[:TRAIN_SIZE], y[TRAIN_SIZE:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "set(chain(*y_train)), set(chain(*y_test)), len(y_train), len(y_test), m.TagClass.RARE_CASES"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "({'NA', 'ablt', 'accs', 'datv', 'gent', 'loct', 'nomn'},\n",
        " {'NA', 'ablt', 'accs', 'datv', 'gent', 'loct', 'nomn'},\n",
        " 7247,\n",
        " 94,\n",
        " {'gen1': 'gent',\n",
        "  'gen2': 'gent',\n",
        "  'loc1': 'loct',\n",
        "  'loc2': 'loct',\n",
        "  'acc2': 'accs',\n",
        "  'acc1': 'accs',\n",
        "  'voct': 'nomn'})"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "THRESH = 0.1\n",
      "FORBIDDEN_GRAMMEMES = {} # {'inan', 'anim', 'sing', 'plur', 'masc', 'femn', 'neut'}\n",
      "# ALLOWED_GRAMMEMES = (m.TagClass.CASES | m.TagClass.PARTS_OF_SPEECH |\n",
      "#                      m.TagClass.TRANSITIVITY | m.TagClass.VOICES | m.TagClass.ASPECTS |\n",
      "#                      m.TagClass.INVOLVEMENT | m.TagClass.MOODS)\n",
      "\n",
      "def _add_grammeme_features(token, namespace, features, k=1):\n",
      "    for p in m.parse(token):\n",
      "        if p.score < THRESH:\n",
      "            continue\n",
      "        for grammeme in p.tag.grammemes:\n",
      "            if grammeme in FORBIDDEN_GRAMMEMES:\n",
      "                continue\n",
      "            key = \"%s:%s\" % (namespace, grammeme)\n",
      "            features[key] = max(p.score*k, features[key])\n",
      "            if p.score == 1:\n",
      "                features['unambig:'+key] = 1\n",
      "            \n",
      "            seen = set()\n",
      "            for grammeme2 in p.tag.grammemes:\n",
      "                if grammeme2 == grammeme:\n",
      "                    continue                \n",
      "                if grammeme2 in FORBIDDEN_GRAMMEMES:\n",
      "                    continue\n",
      "                    \n",
      "                if grammeme > grammeme2:\n",
      "                    key2 = \"%s:%s,%s\" % (namespace, grammeme, grammeme2)\n",
      "                else:\n",
      "                    key2 = \"%s:%s,%s\" % (namespace, grammeme2, grammeme)\n",
      "                    \n",
      "                if key2 in seen:\n",
      "                    continue\n",
      "                seen.add(key2)\n",
      "                features[key2] = max(p.score*k, features[key2])\n",
      "            \n",
      "                if p.score == 1:\n",
      "                    features['unambig:'+key2] = 1\n",
      "            \n",
      "    \n",
      "\n",
      "def get_features(tokens, i):\n",
      "    token = tokens[i]\n",
      "    features = defaultdict(float)\n",
      "    features['bias'] = 1\n",
      "    \n",
      "    features['i:token:%s' % token.lower()] = 1\n",
      "    _add_grammeme_features(token, \"i\", features, k=2)  # WAS: k=2\n",
      "            \n",
      "    if i > 0:\n",
      "        token = tokens[i-1]\n",
      "        features['i-1:token:%s' % token.lower()] = 1\n",
      "#         features['i-1:bigram:%s/%s' % (token.lower(), tokens[i][0].lower())] = 1\n",
      "        _add_grammeme_features(token, \"i-1\", features)                \n",
      "    else:\n",
      "        features['BOS'] = 1\n",
      "                \n",
      "    if i > 1:\n",
      "        token = tokens[i-2]\n",
      "        features['i-2:token:%s' % token.lower()] = 1\n",
      "#         features['i-2:bigram:%s/%s' % (token.lower(), tokens[i-1][0].lower())] = 1\n",
      "        _add_grammeme_features(token, \"i-2\", features)\n",
      "\n",
      "    if i < len(tokens) - 1:\n",
      "        token = tokens[i+1]\n",
      "        features['i+1:token:%s' % token.lower()] = 1\n",
      "        _add_grammeme_features(token, \"i+1\", features)                \n",
      "    else:\n",
      "        features['EOS'] = 1\n",
      "\n",
      "#     if i < len(tokens) - 2:\n",
      "#         token = tokens[i+2]\n",
      "#         features['i+2:token:%s' % token.lower()] = 1\n",
      "#         _add_grammeme_features(token, \"i+2\", features)                \n",
      "\n",
      "    return dict(features)\n",
      "\n",
      "def tokens2features(tokens):\n",
      "    return [get_features(tokens, i) for i in range(len(tokens))]\n",
      "\n",
      "def sent2features(sent):\n",
      "    return tokens2features(sent2tokens(sent))\n",
      "\n",
      "def sent2tokens(sent):\n",
      "    return [item[0] for item in sent]\n",
      "\n",
      "def sent2y(sent):\n",
      "    return [item[1] for item in sent]\n",
      "\n",
      "def getX(sents):\n",
      "    return [sent2features(s) for s in sents]\n",
      "\n",
      "X_train, X_test = getX(sents_train), getX(sents_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pycrfsuite\n",
      "\n",
      "class LessNoisyTrainer(pycrfsuite.Trainer):\n",
      "    \n",
      "    def on_iteration(self, log, info):\n",
      "        if 'avg_precision' in info:\n",
      "            print((\"Iter {num:<3} \"\n",
      "                   \"time={time:<5.2f} \"\n",
      "                   \"loss={loss:<8.2f} \"\n",
      "                   \"active={active_features:<5} \"\n",
      "    #                \"feature_norm={feature_norm:<8.2f} \"\n",
      "                   \"precision={avg_precision:0.3f}  \"\n",
      "                   \"recall={avg_recall:0.3f}  \"\n",
      "                   \"F1={avg_f1:0.3f}  \"\n",
      "                   \"accuracy(item/instance)=\"\n",
      "                   \"{item_accuracy_float:0.3f} {instance_accuracy_float:0.3f}\"\n",
      "                ).format(**info).strip())\n",
      "        else:\n",
      "            print((\"Iter {num:<3} \"\n",
      "                   \"time={time:<5.2f} \"\n",
      "                   \"loss={loss:<8.2f} \"\n",
      "                   \"active={active_features:<5} \"\n",
      "                   \"feature_norm={feature_norm:<8.2f} \"\n",
      "                ).format(**info).strip())\n",
      "            \n",
      "\n",
      "trainer = LessNoisyTrainer('lbfgs')\n",
      "\n",
      "for xseq, yseq in zip(X_train, y_train):\n",
      "    trainer.append(xseq, yseq)\n",
      "    \n",
      "for xseq, yseq in zip(X_test, y_test):\n",
      "    trainer.append(xseq, yseq, 1)\n",
      "\n",
      "# for xseq, yseq in zip(X_test, y_test):\n",
      "#     trainer.append(xseq, yseq)\n",
      "\n",
      "trainer.set_params({\n",
      "    'max_iterations': 80,\n",
      "#     'epsilon': 1e-6,\n",
      "#     'c': 10,\n",
      "#     'type': 2,\n",
      "   'c1': 0.5,\n",
      "   'c2': 0.01,\n",
      "#     'feature.minfreq': 0.05,\n",
      "})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "trainer.train('models/model-12.crfsuite', 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Holdout group: 2\n",
        "\n",
        "Feature generation\n",
        "type: CRF1d\n",
        "feature.minfreq: 0.000000\n",
        "feature.possible_states: 0\n",
        "feature.possible_transitions: 0\n",
        "0.."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "..1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".3.."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "..4."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...5"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "....6."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...7."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...8."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...9."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...10\n",
        "Number of features: 76218\n",
        "Seconds required: 0.664\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "L-BFGS optimization\n",
        "c1: 0.500000\n",
        "c2: 0.010000\n",
        "num_memories: 6\n",
        "max_iterations: 80\n",
        "epsilon: 0.000010\n",
        "stop: 10\n",
        "delta: 0.000010\n",
        "linesearch: MoreThuente\n",
        "linesearch.max_iterations: 20\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter 1   time=0.29  loss=40464.15 active=72954 precision=0.177  recall=0.195  F1=0.172  accuracy(item/instance)=0.587 0.064\n",
        "Iter 2   time=0.16  loss=23168.03 active=63122 precision=0.420  recall=0.274  F1=0.263  accuracy(item/instance)=0.656 0.064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 3   time=0.15  loss=13166.67 active=47141 precision=0.710  recall=0.458  F1=0.531  accuracy(item/instance)=0.732 0.106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 4   time=0.15  loss=7126.84  active=38856 precision=0.867  recall=0.621  F1=0.691  accuracy(item/instance)=0.812 0.191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 5   time=0.15  loss=4448.16  active=32083 precision=0.853  recall=0.707  F1=0.761  accuracy(item/instance)=0.843 0.202"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 6   time=0.15  loss=3049.74  active=26492 precision=0.860  recall=0.759  F1=0.802  accuracy(item/instance)=0.866 0.213"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 7   time=0.15  loss=2177.61  active=20985 precision=0.866  recall=0.794  F1=0.824  accuracy(item/instance)=0.884 0.245"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 8   time=0.15  loss=1718.15  active=18228 precision=0.847  recall=0.811  F1=0.827  accuracy(item/instance)=0.883 0.255"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 9   time=0.15  loss=1487.90  active=17569 precision=0.868  recall=0.832  F1=0.847  accuracy(item/instance)=0.900 0.298"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 10  time=0.15  loss=1349.15  active=16672 precision=0.867  recall=0.847  F1=0.856  accuracy(item/instance)=0.905 0.319"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 11  time=0.15  loss=1200.60  active=14921 precision=0.867  recall=0.846  F1=0.854  accuracy(item/instance)=0.906 0.340"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 12  time=0.15  loss=1096.36  active=14279 precision=0.867  recall=0.850  F1=0.858  accuracy(item/instance)=0.907 0.351"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 13  time=0.15  loss=1013.57  active=13417 precision=0.865  recall=0.851  F1=0.857  accuracy(item/instance)=0.907 0.340"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 14  time=0.16  loss=1001.49  active=10466 precision=0.856  recall=0.853  F1=0.853  accuracy(item/instance)=0.907 0.351"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 15  time=0.16  loss=865.10   active=11436 precision=0.865  recall=0.850  F1=0.857  accuracy(item/instance)=0.909 0.340"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 16  time=0.15  loss=852.67   active=11228 precision=0.865  recall=0.850  F1=0.857  accuracy(item/instance)=0.910 0.351"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 17  time=0.15  loss=791.34   active=9391  precision=0.869  recall=0.862  F1=0.865  accuracy(item/instance)=0.915 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 18  time=0.30  loss=771.47   active=8844  precision=0.885  recall=0.865  F1=0.874  accuracy(item/instance)=0.922 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 19  time=0.15  loss=733.32   active=8693  precision=0.875  recall=0.862  F1=0.868  accuracy(item/instance)=0.917 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 20  time=0.15  loss=711.92   active=8326  precision=0.875  recall=0.861  F1=0.867  accuracy(item/instance)=0.917 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 21  time=0.15  loss=683.12   active=7585  precision=0.880  recall=0.869  F1=0.874  accuracy(item/instance)=0.918 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 22  time=0.15  loss=663.55   active=7395  precision=0.883  recall=0.872  F1=0.877  accuracy(item/instance)=0.921 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 23  time=0.15  loss=650.33   active=7185  precision=0.883  recall=0.872  F1=0.877  accuracy(item/instance)=0.921 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 24  time=0.15  loss=629.06   active=6624  precision=0.888  recall=0.876  F1=0.881  accuracy(item/instance)=0.923 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 25  time=0.15  loss=610.88   active=5691  precision=0.889  recall=0.877  F1=0.882  accuracy(item/instance)=0.923 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 26  time=0.15  loss=601.03   active=5219  precision=0.901  recall=0.880  F1=0.890  accuracy(item/instance)=0.927 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 27  time=0.15  loss=593.95   active=4968  precision=0.901  recall=0.880  F1=0.890  accuracy(item/instance)=0.927 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 28  time=0.15  loss=582.80   active=4260  precision=0.901  recall=0.881  F1=0.890  accuracy(item/instance)=0.927 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 29  time=0.15  loss=582.07   active=3900  precision=0.901  recall=0.879  F1=0.889  accuracy(item/instance)=0.926 0.447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 30  time=0.15  loss=574.57   active=4015  precision=0.901  recall=0.883  F1=0.891  accuracy(item/instance)=0.928 0.447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 31  time=0.16  loss=571.51   active=3888  precision=0.900  recall=0.882  F1=0.890  accuracy(item/instance)=0.927 0.447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 32  time=0.15  loss=566.07   active=3584  precision=0.901  recall=0.881  F1=0.891  accuracy(item/instance)=0.927 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 33  time=0.15  loss=563.73   active=3045  precision=0.900  recall=0.884  F1=0.891  accuracy(item/instance)=0.926 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 34  time=0.15  loss=558.88   active=3425  precision=0.904  recall=0.883  F1=0.893  accuracy(item/instance)=0.928 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 35  time=0.15  loss=558.01   active=3409  precision=0.899  recall=0.880  F1=0.889  accuracy(item/instance)=0.925 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 36  time=0.15  loss=556.29   active=3219  precision=0.901  recall=0.882  F1=0.891  accuracy(item/instance)=0.927 0.436"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 37  time=0.15  loss=554.10   active=3087  precision=0.899  recall=0.880  F1=0.889  accuracy(item/instance)=0.925 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 38  time=0.15  loss=551.21   active=2862  precision=0.899  recall=0.881  F1=0.889  accuracy(item/instance)=0.925 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 39  time=0.15  loss=549.01   active=2852  precision=0.900  recall=0.880  F1=0.889  accuracy(item/instance)=0.925 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 40  time=0.15  loss=547.49   active=2768  precision=0.899  recall=0.881  F1=0.890  accuracy(item/instance)=0.925 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 41  time=0.15  loss=545.68   active=2694  precision=0.901  recall=0.882  F1=0.891  accuracy(item/instance)=0.926 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 42  time=0.15  loss=543.68   active=2540  precision=0.900  recall=0.882  F1=0.891  accuracy(item/instance)=0.926 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 43  time=0.15  loss=542.22   active=2444  precision=0.909  recall=0.886  F1=0.897  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 44  time=0.15  loss=540.73   active=2380  precision=0.907  recall=0.888  F1=0.897  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 45  time=0.15  loss=539.62   active=2421  precision=0.907  recall=0.886  F1=0.896  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 46  time=0.15  loss=538.24   active=2340  precision=0.908  recall=0.889  F1=0.898  accuracy(item/instance)=0.931 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 47  time=0.15  loss=537.19   active=2144  precision=0.906  recall=0.885  F1=0.895  accuracy(item/instance)=0.929 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 48  time=0.15  loss=535.49   active=2305  precision=0.902  recall=0.886  F1=0.893  accuracy(item/instance)=0.928 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 49  time=0.15  loss=534.74   active=2261  precision=0.903  recall=0.886  F1=0.894  accuracy(item/instance)=0.928 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 50  time=0.15  loss=533.37   active=2148  precision=0.905  recall=0.889  F1=0.897  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 51  time=0.15  loss=532.46   active=2101  precision=0.905  recall=0.886  F1=0.895  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 52  time=0.15  loss=531.51   active=2090  precision=0.906  recall=0.890  F1=0.897  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 53  time=0.16  loss=530.57   active=2106  precision=0.905  recall=0.888  F1=0.896  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 54  time=0.16  loss=529.96   active=2064  precision=0.904  recall=0.887  F1=0.895  accuracy(item/instance)=0.929 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 55  time=0.29  loss=529.34   active=1979  precision=0.905  recall=0.887  F1=0.895  accuracy(item/instance)=0.929 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 56  time=0.15  loss=528.65   active=1963  precision=0.904  recall=0.889  F1=0.896  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 57  time=0.15  loss=527.89   active=1986  precision=0.905  recall=0.888  F1=0.896  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 58  time=0.15  loss=527.41   active=1948  precision=0.905  recall=0.889  F1=0.897  accuracy(item/instance)=0.930 0.426"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 59  time=0.15  loss=526.77   active=1922  precision=0.904  recall=0.888  F1=0.896  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 60  time=0.15  loss=526.30   active=1883  precision=0.904  recall=0.889  F1=0.896  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 61  time=0.15  loss=525.87   active=1866  precision=0.906  recall=0.889  F1=0.897  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 62  time=0.15  loss=525.33   active=1844  precision=0.904  recall=0.889  F1=0.896  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 63  time=0.15  loss=525.06   active=1809  precision=0.906  recall=0.889  F1=0.897  accuracy(item/instance)=0.930 0.415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 64  time=0.15  loss=524.57   active=1793  precision=0.904  recall=0.890  F1=0.897  accuracy(item/instance)=0.930 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 65  time=0.15  loss=524.11   active=1761  precision=0.905  recall=0.887  F1=0.896  accuracy(item/instance)=0.929 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 66  time=0.15  loss=523.60   active=1726  precision=0.905  recall=0.890  F1=0.897  accuracy(item/instance)=0.930 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 67  time=0.15  loss=523.35   active=1709  precision=0.907  recall=0.888  F1=0.897  accuracy(item/instance)=0.930 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 68  time=0.16  loss=522.90   active=1684  precision=0.901  recall=0.889  F1=0.895  accuracy(item/instance)=0.929 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 69  time=0.15  loss=522.72   active=1678  precision=0.908  recall=0.889  F1=0.898  accuracy(item/instance)=0.930 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 70  time=0.15  loss=522.29   active=1687  precision=0.902  recall=0.889  F1=0.895  accuracy(item/instance)=0.928 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 71  time=0.15  loss=522.03   active=1679  precision=0.904  recall=0.888  F1=0.895  accuracy(item/instance)=0.929 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 72  time=0.15  loss=521.74   active=1654  precision=0.905  recall=0.891  F1=0.897  accuracy(item/instance)=0.930 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 73  time=0.15  loss=521.57   active=1675  precision=0.905  recall=0.890  F1=0.897  accuracy(item/instance)=0.930 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 74  time=0.15  loss=521.13   active=1666  precision=0.905  recall=0.891  F1=0.897  accuracy(item/instance)=0.930 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 75  time=0.15  loss=520.96   active=1658  precision=0.905  recall=0.888  F1=0.896  accuracy(item/instance)=0.930 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 76  time=0.15  loss=520.68   active=1647  precision=0.904  recall=0.888  F1=0.896  accuracy(item/instance)=0.930 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 77  time=0.15  loss=520.48   active=1630  precision=0.905  recall=0.888  F1=0.896  accuracy(item/instance)=0.930 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 78  time=0.15  loss=520.27   active=1619  precision=0.904  recall=0.888  F1=0.895  accuracy(item/instance)=0.929 0.394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 79  time=0.15  loss=520.11   active=1611  precision=0.907  recall=0.890  F1=0.898  accuracy(item/instance)=0.930 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 80  time=0.15  loss=519.81   active=1608  precision=0.905  recall=0.889  F1=0.897  accuracy(item/instance)=0.930 0.404"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "L-BFGS terminated with the maximum number of iterations\n",
        "Total seconds required for training: 12.607\n",
        "\n",
        "Storing the model\n",
        "Number of active features: 1608 (76218)\n",
        "Number of active attributes: 1003 (53000)\n",
        "Number of active labels: 7 (7)\n",
        "Writing labels\n",
        "Writing attributes\n",
        "Writing feature references for transitions\n",
        "Writing feature references for attributes\n",
        "Seconds required: 0.004\n",
        "\n",
        "CPU times: user 13.3 s, sys: 28.3 ms, total: 13.3 s\n",
        "Wall time: 13.3 s\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trainer.get_params()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "{'feature.possible_transitions': False,\n",
        " 'feature.minfreq': 0.0,\n",
        " 'averaging': True,\n",
        " 'error_sensitive': True,\n",
        " 'epsilon': 0.0,\n",
        " 'type': 1,\n",
        " 'feature.possible_states': False,\n",
        " 'c': 1.0,\n",
        " 'max_iterations': 100}"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tagger = pycrfsuite.Tagger()\n",
      "tagger.open('models/model-12.crfsuite')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "<contextlib.closing at 0x11b3fa898>"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "info = tagger.info()\n",
      "from collections import Counter\n",
      "\n",
      "cnt_trans = Counter(info.transitions)\n",
      "cnt_state = Counter(info.state_features)\n",
      "\n",
      "print(len(cnt_state))\n",
      "\n",
      "# Counter(info.transitions).most_common()\n",
      "# info.state_features\n",
      "[v for v in cnt_state.most_common() if 'i+1' in v[0][0]]\n",
      "# cnt_trans.most_common()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1581\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "[(('i+1:token:\u043d\u0435\u0442', 'gent'), 2.288968),\n",
        " (('i+1:token:\u0432\u0435\u0440\u0443\u044e\u0449\u0438\u0445', 'nomn'), 1.691828),\n",
        " (('i+1:token:\u0443\u0434\u0430\u043b\u043e\u0441\u044c', 'accs'), 1.515406),\n",
        " (('i+1:tran,past', 'accs'), 1.440138),\n",
        " (('i+1:token:\u0433\u043e\u0439\u0438', 'accs'), 1.362639),\n",
        " (('i+1:plur,loct', 'loct'), 1.303974),\n",
        " (('i+1:pres,PRED', 'accs'), 1.289763),\n",
        " (('i+1:PRED', 'accs'), 1.289763),\n",
        " (('i+1:token:\u0432\u043e', 'nomn'), 1.288892),\n",
        " (('i+1:token:\u0441\u043c\u0438', 'accs'), 1.222256),\n",
        " (('i+1:sing,neut', 'nomn'), 1.184623),\n",
        " (('i+1:gent,femn', 'gent'), 1.178066),\n",
        " (('i+1:tran,sing', 'nomn'), 0.841253),\n",
        " (('i+1:plur,NOUN', 'datv'), 0.830829),\n",
        " (('i+1:token:\u0434\u0435\u043b\u044f\u0442\u0441\u044f', 'nomn'), 0.819733),\n",
        " (('i+1:ablt', 'ablt'), 0.803521),\n",
        " (('i+1:token:\u0434\u043e\u043b\u043b\u0430\u0440\u043e\u0432', 'accs'), 0.734435),\n",
        " (('i+1:nomn,inan', 'accs'), 0.6923),\n",
        " (('i+1:token:\u00bb', 'gent'), 0.652834),\n",
        " (('i+1:token:\u043e\u0442\u0446\u0430', 'nomn'), 0.652232),\n",
        " (('i+1:ablt,NOUN', 'ablt'), 0.651724),\n",
        " (('i+1:token:\u0441\u043b\u043e\u0432\u0430', 'nomn'), 0.648005),\n",
        " (('unambig:i+1:PREP', 'nomn'), 0.644428),\n",
        " (('i+1:token:!', 'nomn'), 0.631411),\n",
        " (('i+1:plur,intr', 'nomn'), 0.624259),\n",
        " (('unambig:i+1:nomn,NPRO', 'accs'), 0.61257),\n",
        " (('i+1:token:(', 'nomn'), 0.595053),\n",
        " (('i+1:tran,perf', 'datv'), 0.586776),\n",
        " (('i+1:sing,ablt', 'ablt'), 0.549345),\n",
        " (('i+1:nomn,NPRO', 'accs'), 0.506453),\n",
        " (('i+1:sing,intr', 'gent'), 0.496372),\n",
        " (('unambig:i+1:plur,NOUN', 'datv'), 0.48482),\n",
        " (('i+1:perf,VERB', 'accs'), 0.484366),\n",
        " (('i+1:token:\u0434\u043e\u043b\u043e\u0439', 'accs'), 0.48022),\n",
        " (('i+1:token:\u0440\u0430\u0437\u043c\u0435\u0441\u0442\u0438\u0442\u044c', 'datv'), 0.456536),\n",
        " (('i+1:token:\u2013', 'nomn'), 0.433852),\n",
        " (('i+1:pres,plur', 'nomn'), 0.418582),\n",
        " (('i+1:token:\u043f\u043e\u043b\u043d\u043e\u043c\u043e\u0447\u0438\u0439', 'datv'), 0.416333),\n",
        " (('i+1:token:.', 'gent'), 0.416112),\n",
        " (('i+1:datv,NOUN', 'datv'), 0.413876),\n",
        " (('i+1:sing,gent', 'nomn'), 0.402088),\n",
        " (('i+1:token:\u043e\u0431\u043c\u0435\u043d\u0430', 'accs'), 0.399915),\n",
        " (('unambig:i+1:perf,past', 'gent'), 0.397775),\n",
        " (('unambig:i+1:NPRO', 'accs'), 0.396441),\n",
        " (('unambig:i+1:tran', 'accs'), 0.393595),\n",
        " (('i+1:token:\u0441\u043e\u0441\u0442\u043e\u044f\u0442', 'nomn'), 0.390645),\n",
        " (('i+1:token:\u0441\u043a\u0430\u0437\u0430\u043b', 'accs'), 0.38767),\n",
        " (('unambig:i+1:PREP', 'ablt'), 0.381042),\n",
        " (('i+1:pres', 'accs'), 0.375104),\n",
        " (('unambig:i+1:nomn,NOUN', 'nomn'), 0.367856),\n",
        " (('i+1:token:\u043a', 'accs'), 0.360659),\n",
        " (('i+1:sing,masc', 'nomn'), 0.347802),\n",
        " (('i+1:tran', 'accs'), 0.344996),\n",
        " (('unambig:i+1:ADVB', 'accs'), 0.34184),\n",
        " (('i+1:inan,gent', 'gent'), 0.323985),\n",
        " (('i+1:token:-', 'nomn'), 0.321924),\n",
        " (('unambig:i+1:plur,neut', 'datv'), 0.315518),\n",
        " (('i+1:sing', 'NA'), 0.306264),\n",
        " (('unambig:i+1:masc', 'loct'), 0.294218),\n",
        " (('i+1:masc', 'nomn'), 0.271894),\n",
        " (('i+1:gent', 'nomn'), 0.267171),\n",
        " (('i+1:token:\u043d\u0438\u043a\u0442\u043e', 'accs'), 0.246677),\n",
        " (('i+1:plur,neut', 'datv'), 0.242304),\n",
        " (('i+1:token:,', 'accs'), 0.240847),\n",
        " (('unambig:i+1:sing,NPRO', 'accs'), 0.238548),\n",
        " (('i+1:token:\u043d\u0430', 'gent'), 0.234454),\n",
        " (('i+1:nomn', 'accs'), 0.22875),\n",
        " (('i+1:plur,impf', 'nomn'), 0.221098),\n",
        " (('unambig:i+1:tran,past', 'accs'), 0.213733),\n",
        " (('i+1:masc,NOUN', 'NA'), 0.213102),\n",
        " (('i+1:masc,anim', 'nomn'), 0.208535),\n",
        " (('i+1:sing,masc', 'NA'), 0.206331),\n",
        " (('i+1:sing,NOUN', 'nomn'), 0.203093),\n",
        " (('i+1:femn', 'datv'), 0.200229),\n",
        " (('i+1:masc,inan', 'accs'), 0.192172),\n",
        " (('unambig:i+1:tran,VERB', 'accs'), 0.189822),\n",
        " (('i+1:token:,', 'NA'), 0.187897),\n",
        " (('unambig:i+1:past', 'gent'), 0.181775),\n",
        " (('unambig:i+1:PNCT', 'nomn'), 0.176465),\n",
        " (('i+1:PNCT', 'nomn'), 0.176465),\n",
        " (('i+1:NOUN', 'NA'), 0.169554),\n",
        " (('i+1:impf,INFN', 'NA'), 0.167394),\n",
        " (('unambig:i+1:sing,perf', 'gent'), 0.163166),\n",
        " (('unambig:i+1:perf,VERB', 'accs'), 0.160162),\n",
        " (('i+1:token:\u0438', 'gent'), 0.149398),\n",
        " (('unambig:i+1:impf,INFN', 'NA'), 0.148716),\n",
        " (('unambig:i+1:indc,impf', 'nomn'), 0.147661),\n",
        " (('i+1:nomn', 'NA'), 0.143262),\n",
        " (('unambig:i+1:impf,VERB', 'nomn'), 0.139295),\n",
        " (('i+1:anim', 'nomn'), 0.136082),\n",
        " (('i+1:sing,femn', 'datv'), 0.135606),\n",
        " (('i+1:token:\u0434\u0430\u0440\u043e\u0432\u0430\u043b\u0438', 'datv'), 0.120016),\n",
        " (('i+1:sing,indc', 'nomn'), 0.114252),\n",
        " (('unambig:i+1:sing,masc', 'loct'), 0.111306),\n",
        " (('i+1:indc,impf', 'nomn'), 0.110578),\n",
        " (('i+1:masc,NOUN', 'accs'), 0.109333),\n",
        " (('i+1:PRCL', 'gent'), 0.108969),\n",
        " (('i+1:impf,VERB', 'nomn'), 0.104357),\n",
        " (('i+1:token:\u043d\u0430', 'datv'), 0.100836),\n",
        " (('i+1:sing,nomn', 'NA'), 0.100272),\n",
        " (('unambig:i+1:ablt,NOUN', 'ablt'), 0.100031),\n",
        " (('i+1:tran,VERB', 'accs'), 0.098935),\n",
        " (('i+1:token:\u0432', 'ablt'), 0.092353),\n",
        " (('unambig:i+1:inan,ablt', 'ablt'), 0.091448),\n",
        " (('unambig:i+1:perf', 'gent'), 0.09123),\n",
        " (('unambig:i+1:sing,masc', 'nomn'), 0.09029),\n",
        " (('unambig:i+1:VERB,3per', 'nomn'), 0.089463),\n",
        " (('unambig:i+1:indc,3per', 'nomn'), 0.089463),\n",
        " (('i+1:sing', 'nomn'), 0.082457),\n",
        " (('i+1:token:\u2014', 'nomn'), 0.079017),\n",
        " (('i+1:plur,indc', 'accs'), 0.078938),\n",
        " (('i+1:NOUN', 'nomn'), 0.076559),\n",
        " (('i+1:token:\u043e', 'accs'), 0.071333),\n",
        " (('i+1:token:.', 'ablt'), 0.071133),\n",
        " (('i+1:tran,indc', 'accs'), 0.070858),\n",
        " (('i+1:nomn,NOUN', 'nomn'), 0.070856),\n",
        " (('i+1:perf,indc', 'accs'), 0.069559),\n",
        " (('i+1:tran', 'datv'), 0.067555),\n",
        " (('i+1:past,intr', 'gent'), 0.062804),\n",
        " (('i+1:token:\u0438\u0442\u0430\u043b\u044c\u044f\u043d\u0441\u043a\u043e\u0439', 'accs'), 0.062541),\n",
        " (('i+1:CONJ', 'gent'), 0.052334),\n",
        " (('unambig:i+1:perf,femn', 'gent'), 0.051797),\n",
        " (('i+1:token:\u043e\u0442\u043e\u0433\u043d\u0430\u043b\u0438', 'accs'), 0.050758),\n",
        " (('i+1:token:\u0442\u0430\u043a', 'gent'), 0.049682),\n",
        " (('i+1:sing,PRTS', 'loct'), 0.049141),\n",
        " (('i+1:neut,inan', 'datv'), 0.048047),\n",
        " (('i+1:neut,NOUN', 'datv'), 0.047939),\n",
        " (('i+1:PNCT', 'ablt'), 0.047818),\n",
        " (('unambig:i+1:PNCT', 'ablt'), 0.047818),\n",
        " (('i+1:perf,past', 'gent'), 0.047463),\n",
        " (('i+1:sing,VERB', 'nomn'), 0.046633),\n",
        " (('i+1:perf,femn', 'gent'), 0.045639),\n",
        " (('i+1:perf,PRTS', 'loct'), 0.044676),\n",
        " (('i+1:PRTS', 'loct'), 0.043236),\n",
        " (('i+1:pssv,PRTS', 'loct'), 0.043236),\n",
        " (('i+1:past,PRTS', 'loct'), 0.042991),\n",
        " (('i+1:sing,inan', 'nomn'), 0.041542),\n",
        " (('i+1:plur', 'datv'), 0.036416),\n",
        " (('i+1:token:;', 'accs'), 0.035539),\n",
        " (('i+1:plur,VERB', 'accs'), 0.034053),\n",
        " (('unambig:i+1:sing,PRTS', 'loct'), 0.033871),\n",
        " (('i+1:sing,pssv', 'loct'), 0.032538),\n",
        " (('i+1:sing,nomn', 'accs'), 0.031857),\n",
        " (('unambig:i+1:sing', 'loct'), 0.03116),\n",
        " (('unambig:i+1:tran,sing', 'nomn'), 0.0306),\n",
        " (('i+1:gent,NOUN', 'nomn'), 0.029225),\n",
        " (('unambig:i+1:sing,past', 'gent'), 0.025348),\n",
        " (('i+1:sing,NOUN', 'NA'), 0.022742),\n",
        " (('unambig:i+1:femn', 'gent'), 0.022524),\n",
        " (('i+1:past,femn', 'gent'), 0.021605),\n",
        " (('i+1:pssv,past', 'loct'), 0.021463),\n",
        " (('i+1:pssv,perf', 'loct'), 0.021433),\n",
        " (('i+1:pssv', 'loct'), 0.017543),\n",
        " (('i+1:tran,perf', 'accs'), 0.016391),\n",
        " (('i+1:sing,perf', 'gent'), 0.015025),\n",
        " (('unambig:i+1:past,femn', 'gent'), 0.015003),\n",
        " (('i+1:sing,past', 'nomn'), 0.011323),\n",
        " (('i+1:VERB,3per', 'nomn'), 0.009562),\n",
        " (('i+1:indc,3per', 'nomn'), 0.009562),\n",
        " (('unambig:i+1:PNCT', 'gent'), 0.008193),\n",
        " (('i+1:PNCT', 'gent'), 0.008193),\n",
        " (('i+1:impf,VERB', 'datv'), 0.007971),\n",
        " (('i+1:past', 'gent'), 0.007927),\n",
        " (('i+1:neut,PRTS', 'loct'), 0.007922),\n",
        " (('unambig:i+1:sing,pssv', 'loct'), 0.007271),\n",
        " (('unambig:i+1:PRTS', 'loct'), 0.006775),\n",
        " (('unambig:i+1:pssv,PRTS', 'loct'), 0.006775),\n",
        " (('unambig:i+1:perf,PRTS', 'loct'), 0.006775),\n",
        " (('unambig:i+1:past,PRTS', 'loct'), 0.006775),\n",
        " (('i+1:pssv,neut', 'loct'), 0.0065),\n",
        " (('i+1:neut', 'nomn'), 0.006228),\n",
        " (('unambig:i+1:neut,NOUN', 'datv'), 0.006094),\n",
        " (('unambig:i+1:neut,inan', 'datv'), 0.006094),\n",
        " (('i+1:indc,impf', 'datv'), 0.003808),\n",
        " (('unambig:i+1:pssv', 'loct'), 0.003203),\n",
        " (('unambig:i+1:pssv,past', 'loct'), 0.00311),\n",
        " (('unambig:i+1:pssv,perf', 'loct'), 0.00311),\n",
        " (('unambig:i+1:inan,NOUN', 'datv'), 0.001504),\n",
        " (('unambig:i+1:inan', 'datv'), 0.001504),\n",
        " (('unambig:i+1:sing,indc', 'nomn'), 0.001162),\n",
        " (('i+1:masc,inan', 'NA'), 0.00101),\n",
        " (('i+1:token:\u043d\u0430\u0439\u0434\u0435\u043d\u043e', 'loct'), 0.000902),\n",
        " (('i+1:masc', 'NA'), 0.000818),\n",
        " (('unambig:i+1:neut,PRTS', 'loct'), 0.00033),\n",
        " (('unambig:i+1:pssv,neut', 'loct'), 0.00033),\n",
        " (('i+1:PREP', 'gent'), 0.000199),\n",
        " (('i+1:token:!', 'datv'), 0.000134),\n",
        " (('unambig:i+1:sing,3per', 'datv'), 6.9e-05),\n",
        " (('i+1:token:\u0445\u0432\u0430\u0442\u0438\u0442', 'gent'), 5.6e-05),\n",
        " (('i+1:indc,VERB', 'nomn'), 4.2e-05),\n",
        " (('i+1:indc', 'nomn'), 4.2e-05),\n",
        " (('i+1:nomn,masc', 'NA'), 1.8e-05),\n",
        " (('i+1:token:?', 'nomn'), 8e-06),\n",
        " (('i+1:token:\u043c\u043e\u0436\u043d\u043e', 'ablt'), 5e-06),\n",
        " (('i+1:pres,PRED', 'ablt'), 5e-06),\n",
        " (('unambig:i+1:PRED', 'ablt'), 5e-06),\n",
        " (('i+1:PRED', 'ablt'), 5e-06),\n",
        " (('unambig:i+1:pres,PRED', 'ablt'), 5e-06),\n",
        " (('i+1:perf,neut', 'datv'), -2e-06),\n",
        " (('unambig:i+1:nomn,NPRO', 'nomn'), -4e-06),\n",
        " (('i+1:past,neut', 'datv'), -4e-06),\n",
        " (('i+1:nomn,NPRO', 'nomn'), -4e-06),\n",
        " (('i+1:gent,anim', 'gent'), -2e-05),\n",
        " (('i+1:plur,inan', 'nomn'), -4.2e-05),\n",
        " (('i+1:PREP', 'accs'), -5.7e-05),\n",
        " (('i+1:token:\u0432\u043e', 'gent'), -7.7e-05),\n",
        " (('i+1:pssv,PRTS', 'datv'), -0.000195),\n",
        " (('i+1:PRTS', 'datv'), -0.000195),\n",
        " (('i+1:past,PRTS', 'datv'), -0.00021),\n",
        " (('i+1:sing,pssv', 'datv'), -0.000249),\n",
        " (('i+1:sing,PRTS', 'datv'), -0.000329),\n",
        " (('i+1:masc,gent', 'gent'), -0.00034),\n",
        " (('i+1:token:,', 'loct'), -0.000437),\n",
        " (('i+1:sing,nomn', 'ablt'), -0.000517),\n",
        " (('i+1:nomn', 'ablt'), -0.001591),\n",
        " (('i+1:sing', 'gent'), -0.001987),\n",
        " (('i+1:inan,femn', 'accs'), -0.002167),\n",
        " (('i+1:indc,impf', 'gent'), -0.002758),\n",
        " (('unambig:i+1:sing,past', 'NA'), -0.002861),\n",
        " (('unambig:i+1:NPRO', 'nomn'), -0.003237),\n",
        " (('unambig:i+1:sing,nomn', 'gent'), -0.003272),\n",
        " (('i+1:pssv,past', 'datv'), -0.003894),\n",
        " (('i+1:inan,gent', 'accs'), -0.004486),\n",
        " (('i+1:NOUN', 'accs'), -0.005825),\n",
        " (('i+1:pssv', 'datv'), -0.006867),\n",
        " (('i+1:intr,3per', 'gent'), -0.007457),\n",
        " (('unambig:i+1:sing', 'gent'), -0.007697),\n",
        " (('unambig:i+1:pres,PRED', 'datv'), -0.010173),\n",
        " (('unambig:i+1:PRED', 'datv'), -0.010173),\n",
        " (('unambig:i+1:tran,INFN', 'nomn'), -0.012126),\n",
        " (('i+1:tran,perf', 'NA'), -0.015474),\n",
        " (('i+1:tran,3per', 'accs'), -0.0168),\n",
        " (('i+1:pres,PRED', 'datv'), -0.020088),\n",
        " (('i+1:PRED', 'datv'), -0.020088),\n",
        " (('i+1:token:\u043c\u043e\u0436\u043d\u043e', 'datv'), -0.022264),\n",
        " (('unambig:i+1:impf', 'gent'), -0.022548),\n",
        " (('i+1:intr,VERB', 'accs'), -0.027518),\n",
        " (('i+1:intr,indc', 'accs'), -0.029484),\n",
        " (('i+1:PNCT', 'datv'), -0.029843),\n",
        " (('unambig:i+1:PNCT', 'datv'), -0.029843),\n",
        " (('i+1:tran,INFN', 'nomn'), -0.030934),\n",
        " (('i+1:token:,', 'datv'), -0.033125),\n",
        " (('i+1:inan,NOUN', 'ablt'), -0.03857),\n",
        " (('i+1:masc', 'ablt'), -0.039614),\n",
        " (('unambig:i+1:sing,femn', 'nomn'), -0.039781),\n",
        " (('i+1:plur,femn', 'accs'), -0.040262),\n",
        " (('i+1:sing,neut', 'datv'), -0.047341),\n",
        " (('unambig:i+1:perf,past', 'nomn'), -0.050348),\n",
        " (('unambig:i+1:sing,neut', 'datv'), -0.052165),\n",
        " (('i+1:VERB,3per', 'accs'), -0.057538),\n",
        " (('i+1:indc,3per', 'accs'), -0.057538),\n",
        " (('i+1:plur', 'gent'), -0.074843),\n",
        " (('i+1:token:,', 'nomn'), -0.076544),\n",
        " (('unambig:i+1:sing,perf', 'datv'), -0.076625),\n",
        " (('unambig:i+1:sing,masc', 'accs'), -0.08331),\n",
        " (('i+1:neut,inan', 'accs'), -0.091215),\n",
        " (('i+1:neut,NOUN', 'accs'), -0.091328),\n",
        " (('i+1:pres', 'gent'), -0.095953),\n",
        " (('unambig:i+1:tran', 'nomn'), -0.098443),\n",
        " (('i+1:femn,NOUN', 'accs'), -0.103198),\n",
        " (('i+1:sing,intr', 'accs'), -0.104592),\n",
        " (('i+1:masc,Name', 'nomn'), -0.113987),\n",
        " (('unambig:i+1:plur,inan', 'nomn'), -0.123),\n",
        " (('unambig:i+1:nomn,masc', 'accs'), -0.131744),\n",
        " (('unambig:i+1:masc', 'accs'), -0.13356),\n",
        " (('i+1:gent', 'gent'), -0.134015),\n",
        " (('i+1:sing,femn', 'nomn'), -0.135355),\n",
        " (('i+1:intr,futr', 'accs'), -0.137973),\n",
        " (('i+1:inan', 'ablt'), -0.140681),\n",
        " (('i+1:sing,Name', 'nomn'), -0.143375),\n",
        " (('i+1:Name,NOUN', 'nomn'), -0.143927),\n",
        " (('i+1:anim,Name', 'nomn'), -0.143927),\n",
        " (('i+1:Name', 'nomn'), -0.143927),\n",
        " (('i+1:ADVB', 'nomn'), -0.147989),\n",
        " (('i+1:pres,intr', 'gent'), -0.154688),\n",
        " (('i+1:intr,impf', 'accs'), -0.158443),\n",
        " (('i+1:sing', 'ablt'), -0.1644),\n",
        " (('unambig:i+1:tran,perf', 'NA'), -0.173491),\n",
        " (('unambig:i+1:inan,gent', 'nomn'), -0.188684),\n",
        " (('unambig:i+1:gent,NOUN', 'nomn'), -0.189692),\n",
        " (('unambig:i+1:ADVB', 'gent'), -0.190897),\n",
        " (('unambig:i+1:gent', 'nomn'), -0.19634),\n",
        " (('i+1:token:;', 'nomn'), -0.21116),\n",
        " (('i+1:PNCT', 'accs'), -0.219205),\n",
        " (('unambig:i+1:PNCT', 'accs'), -0.219205),\n",
        " (('i+1:LATN', 'nomn'), -0.223452),\n",
        " (('i+1:neut', 'gent'), -0.239619),\n",
        " (('unambig:i+1:LATN', 'nomn'), -0.24002),\n",
        " (('i+1:token:.', 'accs'), -0.242673),\n",
        " (('i+1:sing,perf', 'datv'), -0.263939),\n",
        " (('i+1:token:\u0438', 'accs'), -0.264701),\n",
        " (('unambig:i+1:neut', 'gent'), -0.272856),\n",
        " (('i+1:loct', 'gent'), -0.277228),\n",
        " (('i+1:tran,plur', 'nomn'), -0.32782),\n",
        " (('unambig:i+1:tran,plur', 'nomn'), -0.334781),\n",
        " (('i+1:datv,NOUN', 'ablt'), -0.336706),\n",
        " (('i+1:token:!', 'gent'), -0.357485),\n",
        " (('i+1:3per', 'accs'), -0.367748),\n",
        " (('unambig:i+1:past', 'datv'), -0.369937),\n",
        " (('i+1:token:\u2013', 'NA'), -0.4142),\n",
        " (('i+1:NOUN', 'ablt'), -0.437582),\n",
        " (('i+1:token:!', 'accs'), -0.437908),\n",
        " (('i+1:token::', 'accs'), -0.449596),\n",
        " (('unambig:i+1:femn', 'accs'), -0.452156),\n",
        " (('i+1:PREP', 'NA'), -0.457409),\n",
        " (('i+1:impf', 'gent'), -0.47421),\n",
        " (('i+1:token:\u043d\u0430', 'nomn'), -0.478213),\n",
        " (('i+1:sing,3per', 'accs'), -0.489364),\n",
        " (('unambig:i+1:INFN', 'nomn'), -0.503127),\n",
        " (('i+1:masc,inan', 'nomn'), -0.533941),\n",
        " (('i+1:token:.', 'nomn'), -0.53793),\n",
        " (('i+1:intr', 'accs'), -0.554346),\n",
        " (('i+1:INFN', 'nomn'), -0.555237),\n",
        " (('i+1:femn', 'accs'), -0.662948),\n",
        " (('unambig:i+1:PREP', 'datv'), -0.72302),\n",
        " (('i+1:token:\u0438', 'NA'), -0.850481),\n",
        " (('i+1:token:\u0433\u043e\u0439\u0438', 'gent'), -0.907847),\n",
        " (('i+1:token:?', 'NA'), -0.952521),\n",
        " (('i+1:token:\u00bb', 'nomn'), -0.978093),\n",
        " (('i+1:token:\u2026', 'nomn'), -1.024946),\n",
        " (('i+1:token:\u043a', 'gent'), -1.161926),\n",
        " (('i+1:token:(', 'gent'), -1.444748),\n",
        " (('i+1:token:\u00bb', 'NA'), -1.654656),\n",
        " (('i+1:plur', 'ablt'), -1.813446)]"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _best_parse(tok):\n",
      "    try:\n",
      "        return m.parse(tok)[0]\n",
      "    except IndexError:\n",
      "        return m.parse('FOO')[0]\n",
      "    \n",
      "def _partial_tag(y):\n",
      "    return y\n",
      "    return [tag.split(',')[1] for tag in y]\n",
      "\n",
      "def print_results(fp):\n",
      "    fp.write(\"\u0442\u043e\u043a\u0435\u043d                true           crf                pymorphy2        result\\n\")\n",
      "    fp.write(\"=\"*80 + '\\n')\n",
      "    crf_win, crf_err, pym_win, pym_err, fails = 0, 0, 0, 0, 0\n",
      "    for sent in sents_test:\n",
      "        tokens = sent2tokens(sent)\n",
      "        y_true = sent2y(sent)\n",
      "\n",
      "        y_pymorphy2 = [get_outvalue(_best_parse(tok).tag) for tok, _ in sent]\n",
      "        pymorphy2_score = [_best_parse(tok).score for tok, _ in sent]\n",
      "\n",
      "        y_tagger = tagger.tag(sent2features(sent))\n",
      "        tagger_score = [tagger.marginal(y, pos) for pos, y in enumerate(y_tagger)]\n",
      "        \n",
      "        y_true = _partial_tag(y_true)\n",
      "        y_pymorphy2 = _partial_tag(y_pymorphy2)\n",
      "        y_tagger = _partial_tag(y_tagger)\n",
      "\n",
      "        for tok in zip(tokens, y_true, y_tagger, tagger_score, y_pymorphy2, pymorphy2_score):\n",
      "            res = ''\n",
      "            \n",
      "            if tok[1] != tok[2]:\n",
      "                crf_err += 1\n",
      "            \n",
      "            if tok[1] != tok[4]:\n",
      "                pym_err += 1\n",
      "                \n",
      "            if tok[1] == tok[2] and tok[1] != tok[4]:\n",
      "                res = '+crf'                \n",
      "                crf_win += 1\n",
      "            elif tok[1] == tok[4] and tok[1] != tok[2]:\n",
      "                res = '+pym'\n",
      "                pym_win += 1\n",
      "            elif tok[1] != tok[4] and tok[1] != tok[2]:\n",
      "                res = '!'\n",
      "                fails += 1\n",
      "            \n",
      "            tag_scored = \"%-10s %0.3f\" % (tok[2], tok[3])\n",
      "            pym_scored = \"%-10s %0.3f\" % (tok[4], tok[5])\n",
      "            fp.write(\"%-20s %-14s %-18s %-16s %-14s\\n\" % (tok[0], tok[1], tag_scored, pym_scored, res))\n",
      "        fp.write(\"CRF: %s err, fix %s (+%s), pymorphy2: %s err, fix %s, failed: %s\\n\" % (\n",
      "                    crf_err, crf_win, crf_win-pym_win, pym_err, pym_win, fails))\n",
      "        fp.write(\"-\"*70 + '\\n')\n",
      "    \n",
      "    print(\"CRF: %s err, fix %s (+%s), pymorphy2: %s err, fix %s, failed: %s\\n\" % (\n",
      "                crf_err, crf_win, crf_win-pym_win, pym_err, pym_win, fails))\n",
      "    \n",
      "with open('results/res19.txt', 'wt', encoding='utf8') as f:\n",
      "    print_results(f)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CRF: 120 err, fix 100 (+67), pymorphy2: 187 err, fix 33, failed: 87\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pymorphy2.tokenizers import simple_word_tokenize\n",
      "\n",
      "\n",
      "def tag_text(tokens):\n",
      "    features = tokens2features(tokens)\n",
      "    \n",
      "#     print(\"gent\")\n",
      "#     for feat, w in features[2].items():\n",
      "#         if (feat, 'ablt') in info.state_features:\n",
      "#             print(\"%s %s\" % (feat, w * info.state_features[(feat, 'ablt')]))\n",
      "            \n",
      "#     print(\"\\naccs\")\n",
      "#     for feat, w in features[2].items():\n",
      "#         if (feat, 'accs') in info.state_features:\n",
      "#             print(\"%s %s\" % (feat, w * info.state_features[(feat, 'accs')]))\n",
      "    IDX = 0\n",
      "        \n",
      "    print(\"ACTIVE:\")\n",
      "    for feat, w in features[IDX].items():\n",
      "        state_ablt = (feat, 'ablt')\n",
      "        state_datv = (feat, 'datv')\n",
      "        \n",
      "        if state_ablt in info.state_features:\n",
      "            print(\"%s %s\" % (state_ablt, w * info.state_features[state_ablt]))\n",
      "        if state_datv in info.state_features:\n",
      "            print(\"%s %s\" % (state_datv, w * info.state_features[state_datv]))\n",
      "                \n",
      "\n",
      "#     print(\"\\nINACTIVE:\")\n",
      "#     for feat, w in features[2].items():\n",
      "#         if feat in info.attributes:\n",
      "#             print(feat, w)\n",
      "                \n",
      "    \n",
      "    res = tagger.tag(features)\n",
      "    print(tagger.marginal('ablt', IDX))\n",
      "    print(tagger.marginal('datv', IDX))\n",
      "    return res\n",
      "\n",
      "def tag_text_pymorphy2(tokens):\n",
      "    return [get_outvalue(m.parse(tok)[0].tag) for tok in tokens]\n",
      "\n",
      "\n",
      "def demo(text):    \n",
      "    tokens = simple_word_tokenize(text)\n",
      "    for tok, tag_tag, pym_tag in zip(tokens, tag_text(tokens), tag_text_pymorphy2(tokens)):\n",
      "        print(tok, tag_tag, pym_tag, sep='/', end=' ')\n",
      "    \n",
      "#demo('''\u043f\u043e\u0442\u0435\u044f \u043f\u044c\u044e \u043a\u0438\u043d\u0434\u0437\u043c\u0430\u0440\u0430\u0443\u043b\u0438 \u043a\u0440\u0438\u0447\u0443 \u043f\u0435\u0440\u043d\u0430\u0442\u044b\u043c \u0433\u0443\u043b\u0438-\u0433\u0443\u043b\u0438''')\n",
      "#demo(\"\u043d\u0435 \u0432\u0438\u0434\u0438\u0442 \u0431\u0443\u0434\u0443\u0449\u0435\u0433\u043e\")\n",
      "# demo('''\u043d\u0435\u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e \u0443\u043f\u0440\u0435\u043a\u043d\u0443\u0442\u044c \u0432 \u043e\u0442\u043d\u043e\u0448\u0435\u043d\u0438\u0438 \u043a \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u044b\u043c \u0440\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u043e-\u0430\u0437\u0435\u0440\u0431\u0430\u0439\u0434\u0436\u0430\u043d\u0441\u043a\u0438\u043c \u0437\u0430\u043a\u0443\u043b\u0438\u0441\u043d\u044b\u043c \u0434\u043e\u0433\u043e\u0432\u043e\u0440\u0435\u043d\u043d\u043e\u0441\u0442\u044f\u043c''')\n",
      "demo('\u0412 \u043f\u043e\u0441\u0435\u043b\u043a\u0435 \u0414\u0430\u043b\u044c\u043d\u0438\u0439 \u0418\u0440\u043a\u0443\u0442\u0441\u043a\u043e\u0439 \u043e\u0431\u043b\u0430\u0441\u0442\u0438 \u0441\u0433\u043e\u0440\u0435\u043b\u0438 22 \u0436\u0438\u043b\u044b\u0445 \u0434\u043e\u043c\u0430')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ACTIVE:\n",
        "('unambig:i+1:inan,NOUN', 'datv') 0.021008\n",
        "('i+1:NOUN', 'ablt') -0.190759\n",
        "('unambig:i+1:inan', 'datv') 0.021008\n",
        "('BOS', 'datv') 1.307267\n",
        "('i+1:sing', 'ablt') -0.233262\n",
        "1.1282769398169699e-05\n",
        "6.645885861521191e-05\n",
        "\u0412/NA/NA \u043f\u043e\u0441\u0435\u043b\u043a\u0435/loct/loct \u0414\u0430\u043b\u044c\u043d\u0438\u0439/accs/accs \u0418\u0440\u043a\u0443\u0442\u0441\u043a\u043e\u0439/loct/gent \u043e\u0431\u043b\u0430\u0441\u0442\u0438/loct/loct \u0441\u0433\u043e\u0440\u0435\u043b\u0438/NA/NA 22/NA/NA \u0436\u0438\u043b\u044b\u0445/gent/gent \u0434\u043e\u043c\u0430/gent/gent "
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class DisambigCase(object):\n",
      "    def __init__(self, morph, tagger_path):\n",
      "        self.tagger = pycrfsuite.Tagger()\n",
      "        self.tagger.open(tagger_path)\n",
      "        self.morph = morph\n",
      "        \n",
      "    def tag(self, tokens):\n",
      "        if isinstance(tokens, str):\n",
      "            tokens = simple_word_tokenize(tokens)\n",
      "        \n",
      "        unkn = self.morph.parse('FOO')[0]\n",
      "        pym_parses = [self.morph.parse(tok) for tok in tokens]\n",
      "        pym_parses0 = [p[0] if p else unkn for p in pym_parses]\n",
      "        \n",
      "        \n",
      "        return pym_parses0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "disambig = DisambigCase(m, 'models/model-12.crfsuite')\n",
      "disambig.tag(\"\u043f\u043e\u0442\u0435\u044f, \u043f\u044c\u044e \u043a\u0438\u043d\u0434\u0437\u043c\u0430\u0440\u0430\u0443\u043b\u0438 \u043a\u0440\u0438\u0447\u0443 \u043f\u0435\u0440\u043d\u0430\u0442\u044b\u043c \u0433\u0443\u043b\u0438-\u0433\u0443\u043b\u0438\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 34,
       "text": [
        "[Parse(word='\u043f\u043e\u0442\u0435\u044f', tag=OpencorporaTag('GRND,impf,intr pres'), normal_form='\u043f\u043e\u0442\u0435\u0442\u044c', score=1.0, methods_stack=((<DictionaryAnalyzer>, '\u043f\u043e\u0442\u0435\u044f', 14, 67),)),\n",
        " Parse(word=',', tag=OpencorporaTag('PNCT'), normal_form=',', score=1.0, methods_stack=((<PunctuationAnalyzer>, ','),)),\n",
        " Parse(word='\u043f\u044c\u044e', tag=OpencorporaTag('VERB,impf,tran sing,1per,pres,indc'), normal_form='\u043f\u0438\u0442\u044c', score=1.0, methods_stack=((<DictionaryAnalyzer>, '\u043f\u044c\u044e', 442, 1),)),\n",
        " Parse(word='\u043a\u0438\u043d\u0434\u0437\u043c\u0430\u0440\u0430\u0443\u043b\u0438', tag=OpencorporaTag('NOUN,inan,neut,Sgtm,Fixd sing,nomn'), normal_form='\u043a\u0438\u043d\u0434\u0437\u043c\u0430\u0440\u0430\u0443\u043b\u0438', score=0.16666666666666666, methods_stack=((<DictionaryAnalyzer>, '\u043a\u0438\u043d\u0434\u0437\u043c\u0430\u0440\u0430\u0443\u043b\u0438', 146, 0),)),\n",
        " Parse(word='\u043a\u0440\u0438\u0447\u0443', tag=OpencorporaTag('VERB,impf,intr sing,1per,pres,indc'), normal_form='\u043a\u0440\u0438\u0447\u0430\u0442\u044c', score=1.0, methods_stack=((<DictionaryAnalyzer>, '\u043a\u0440\u0438\u0447\u0443', 534, 1),)),\n",
        " Parse(word='\u043f\u0435\u0440\u043d\u0430\u0442\u044b\u043c', tag=OpencorporaTag('ADJF,Qual masc,sing,ablt'), normal_form='\u043f\u0435\u0440\u043d\u0430\u0442\u044b\u0439', score=0.2, methods_stack=((<DictionaryAnalyzer>, '\u043f\u0435\u0440\u043d\u0430\u0442\u044b\u043c', 4, 5),)),\n",
        " Parse(word='\u0433\u0443\u043b\u0438-\u0433\u0443\u043b\u0438', tag=OpencorporaTag('INTJ'), normal_form='\u0433\u0443\u043b\u0438-\u0433\u0443\u043b\u0438', score=1.0, methods_stack=((<DictionaryAnalyzer>, '\u0433\u0443\u043b\u0438-\u0433\u0443\u043b\u0438', 20, 0),))]"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}